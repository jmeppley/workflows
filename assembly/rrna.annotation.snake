include: "../annotation/bwa.snake"

from python.common import get_file_name

# available rRNA DBs
from python.annotate import get_last_alg, get_rna_id_names_file, \
                            get_rna_search_hits

blank_file_name = ".empty.file"
rna_search_hits_template = \
    "contigs.all.vs.rRNA.cmsearch.{rmol}.gt{length}.gff.vs.{db_dot_fmt}"

# this should be set in the wf: assembly/contig.annotation.snake
logger.debug("SAMPLE COVERAGES:\n" + repr(contig_coverage_files))

wildcard_constraints:
    rmol=r'[LS]SU',
    length=r'\d+',

rule long_rrna_gff:
    """ find long LSU or SSU annotations """
    input:
        "{prefix}.gff"
    output:
        "{prefix}.{rmol}.gt{length}.gff"
    benchmark:
        "benchmarks/{prefix}.{rmol}.gt{length}.time"
    version:
        get_version("filter_blast_m8.py")
    shell:
        "grep {wildcards.rmol} {input} \
          | sort \
          | filter_blast_m8.py -s score -L {wildcards.length} -f gff \
            --nonoverlapping \
          > {output} || true"

rule rrna_fasta:
    """ extract rRNA fasta """
    input:
        fasta="{root}.fasta",
        gff="{root}.vs.{search}.gff"
    output:
        "{root}.vs.{search}.gff.fasta"
    benchmark:
        "benchmarks/{root}.vs.{search}.gff.fasta.time"
    version:
        get_version("get_sequences_from_m8.py")
    shell:
        "cat {input.fasta} \
            | get_sequences_from_m8.py -f gff {input.gff} \
            > {output}"

rule dummy_file:
    """ blank file """
    output: blank_file_name
    shell: "touch {output}"

rule rrna_report:
    """
    Look at the rRNA annotations and get table of nearly full length LSUs or SSUs
    """
    input:
        gff="contigs.all.vs.rRNA.cmsearch.{rmol}.gt{length}.gff",
        stats=contig_coverage_files.values(),
        hits=lambda w: get_rna_search_hits(w, config,
                        blank_file_name=blank_file_name,
                        rna_search_hits_template=rna_search_hits_template),
        id_names=lambda w: get_rna_id_names_file(w, config
                                          blank_file_name=blank_file_name),
    output:
        "contigs.all.vs.rRNA.cmsearch.{rmol}.gt{length}.tsv"
    run:
        # get map from contigs to coverage
        coverages = {}
        for sample, stats_file in contig_coverage_files.items():
            cov_table = pandas.read_table(stats_file,
                                          index_col=0,
                                          header=0,
                                         )
            coverages[sample] = cov_table[config['cov_col']]

        # table of rRNA model hits from filtered GFF
        features = pandas.read_table(get_file_name(input.gff),
                                     header=None,
                                     names=['contig',
                                            'tool',
                                            'type',
                                            'start',
                                            'end',
                                            'score',
                                            'notes'],
                                     usecols=[0,1,2,3,4,5,8])

        # add coverages for each sample
        coverage_col_names = []
        for sample, sample_covs in coverages.items():
            col_name = 'cov_{}'.format(sample)
            coverage_col_names.append(col_name)
            features[col_name] = \
                [sample_covs[features.loc[i,'contig']]\
                 for i in features.index]

        # index on contig, start, and end, and just take a few columns
        output_index_columns = ['contig', 'start', 'end']
        output_columns = coverage_col_names + ['type', 'score']
        output_table = features.set_index(output_index_columns)[output_columns]

        # get Silva annotation(s) for each feature
        from edl.blastm8 import generate_hits
        from edl.util import parseMapFile
        
        m = re.search(r'gff\.vs\.(.+)', get_file_name(input.hits))
        if m is not None:
            hit_table_name = re.search(r'gff\.vs\.(.+)', input.hits).group(1)
            # should be, eg, SilvaSSU.lastn or SilvaSSU.bwa.sam
            words = hit_table_name.split('.')
            # first word is DB name
            db = words[0]
            # last word is fmt for parsing
            hit_format = words[-1]
            if hit_format.startswith('last'):
                hit_format = 'last'
            elif hit_format.startswith('blast'):
                hit_format = 'blastplus'
            hit_descriptions = parseMapFile(input.id_names)
            for gene, hits in generate_hits(get_file_name(input.hits),
                                            format=hit_format):
                # take the first hit
                hit = list(hits)[0]
                contig, start, end = re.search(r'^(.+)_(\d+)_(\d+)$', gene)\
                                                                        .groups()
                index = (contig, int(start), int(end))
                if index not in output_table.index:
                    index = (contig, int(end), int(start))
                desc = hit_descriptions[hit.hit]
                output_table.loc[index, db] = desc

        output_table.to_csv(output[0], sep='\t')
