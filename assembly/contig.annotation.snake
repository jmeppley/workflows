"""
Rules that take a contigs.fasta file and generate a bunch of information about
the assembly

 * basic stats
 * assembly stats (N50, etc)
 * identify rRNA genes
 * predict proteins
 * annotate proteins
 * compile summary stats and annotations
"""

include: "../common/mapping_bwa.snake"
from python.common import get_file_name
from python.assembly import get_contig_stats, \
                            generate_histogram, \
                            get_annot_coverage_stats

"""
# Some extra hoops to jump through because the contigs stats aren't a proper 
#  script yet
snakefile_path=os.path.dirname(os.path.abspath(workflow.snakefile))
config['pymg_dir'] = os.path.join(snakefile_path, 'tools', 'pymg')
sys.path.append(config['pymg_dir'])
from edl import __version__ as PYMG_VERSION
"""
include: "contig.genes.snake"
include: "../annotation/lastal.snake"

config.setdefault('outputs', set()).add("contigs.filter.annotations.gff")
config.setdefault('outputs', set()).add("contigs.filter.annotations.fna")
config.setdefault('outputs', set()).add("contigs.all.annotations.coverages.tsv")

contig_coverage_files = \
    {s:'contigs.all.coverages.{sample}.tsv'.format(sample=s) \
     for s in config['sample_data'] \
     if 'clean' in config['sample_data'][s]}

annot_coverage_files = \
    {s:'contigs.all.annotations.coverages.{sample}.tsv' \
       .format(sample=s) \
     for s in config['sample_data'] \
     if 'clean' in config['sample_data'][s]}

include: "rrna.annotation.snake"

rule contig_stats_table:
    """
    Make a table of contig sequence sts (length, gc)
    """
    input:
        "contigs.all.fasta",
    output:
        temp("contigs.all.sequence.stats.txt"),
    benchmark:
        "benchmarks/contig.sequence.stats.time"
    run:
        get_contig_stats(get_file_name(input), get_file_name(output))
        
rule contig_master_stats_table:
    """
    Merge sequence and coverage stats into one table
    """
    input:
        seq="contigs.all.sequence.stats.txt",
        cov=contig_coverage_files.values()
    output:
        'contigs.all.stats.txt'
    benchmark: 'benchmarks/contigs.stats.time'
    run:
        # load sequence stats
        contig_stats = \
            pandas.read_table(get_file_name(input.seq), index_col=0)

        if isinstance(input.cov, str):
            input.cov = [input.cov, ]

        # merge in coverages from each sample
        for sample, cov_file in contig_coverage_files.items():
            cov_stats = pandas.read_table(cov_file, index_col=0)
            cov_stats.columns = ["_".join([sample, c]) \
                                 for c in cov_stats.columns]
            contig_stats = contig_stats.join(cov_stats, how='left')

            # add up read count and mean cov from all samples
            if 'ReadCount' not in contig_stats:
                contig_stats['ReadCount'] = \
                    contig_stats[sample + "_ReadCount"]
                contig_stats['MeanCov'] = \
                    contig_stats[sample + "_MeanCov"]
            else:
                contig_stats['ReadCount'] = \
                    (contig_stats['ReadCount'] + 
                     contig_stats[sample + "_ReadCount"])
                contig_stats['MeanCov'] = \
                    (contig_stats['MeanCov'] + 
                     contig_stats[sample + "_MeanCov"])

        # write table to file
        contig_stats.to_csv(get_file_name(output), sep='\t')

rule sample_annotation_coverage_table:
    """
    Use depths to build table of coverage per gene per sample
    """
    input:
        "mapping/{sample}.reads.vs.{contigs}.depths",
        "{contigs}.annotations.gff"
    output:
        temp("{contigs}.annotations.coverages.{sample}.tsv"),
    benchmark:
        "benchmarks/contig.stats.{sample}.{contigs}.time"
    run:
        print("getting_coverage_stats:")
        get_annot_coverage_stats(*list(input), get_file_name(output))

rule annotation_coverage_table:
    """
    combine sample annotation coverage tables into one
    """
    input:
        annot_coverage_files.values()
    output:
        "contigs.all.annotations.coverages.tsv"
    run:
        # merge in coverages from each sample
        combined_table = None
        for sample, cov_file in annot_coverage_files.items():
            cov_stats = pandas.read_table(cov_file, index_col=0)
            cov_stats.columns = [sample,]

            combined_table = combined_table.join(cov_stats,
                                                 how='outer') \
                             if combined_table is not None \
                             else cov_stats

        # add up samples
        combined_table['total'] = combined_table.sum(axis=1)

        # write table
        combined_table.to_csv(get_file_name(output), sep='\t')

                                     
rule contigs_filter:
    """
    Get list of contigs that pass provided filter:

    Filter defaults to:
        ReadCount>=5
        Length>=2000
    """
    input: "contigs.all.stats.txt"
    output: 
        list="contigs.filter.list",
        table="contigs.final.stats.txt"
    benchmark: 'benchmarks/contig.filter.list.time'
    params:
        cutoffs=config.get('contig_cutoffs', ['ReadCount>=5',
                                              'Length>=2000']),
    run:
        contig_table = pandas.read_table(get_file_name(input), index_col=0)
        for filter_string in params.cutoffs:
            contig_table = contig_table.query(filter_string)
        contig_table.to_csv(get_file_name(output.table), sep='\t')
        with open(get_file_name(output.list), 'wt') as OUT:
            OUT.write('\n'.join(iter(contig_table.index)))
            OUT.write('\n')

rule contig_histogram:
    input:
        "contigs.all.stats.txt"
    output:
        "histograms/contigs_gt_{length_cutoff}/{metric}.hist"
    params:
        width=75,
        log=True
    run:
        generate_histogram(get_file_name(input),
                           get_file_name(output),
                           metric=wildcards.metric,
                           length_cutoff=int(wildcards.length_cutoff),
                           txt_width=params.width,
                           log=params.log)

rule contigs_filtered:
    """
    Get fasta of contigs with config[mapped_read_cutoff] mapped reads
    """
    input: 
        fasta="contigs.all.fasta",
        list="contigs.filter.list"
    output: "contigs.filter.fasta"
    benchmark: "benchmarks/contigs.fitered.fasta.time"
    shell:
        "screen_list.py -k {input.fasta} -l {input.list} -o {output}"

