"""
A makefile to find the best hits of s aset of sequences in a given database

Given:

 * A set of sequences files (eg. {sample}/reads.fastq for N samples)

Do the following for each set of sequences:

 * search against a sequence DB (EG RefSeq or a gene catalog)
 * assign a single top hit to each sequence
 
Optional: rRNA filtering

To also cout a specific subset of reads based on RFAM model filtering,
turn on rrna filtering (remove_rrna=True) and specify one of (non-rRNA 
(default), rRNA-only, SSU, or LSU). An example config snippet:

```
remove_rna: True
rrna_subset: SSU
```

Finally
 * compile a table of hit counts by sample

"""
import re
from python.common import get_version
from python.tophit import get_top_hit_outputs, get_rna_filtered_reads, get_get_ids_cmd
from snakemake.logging import logger

needs_qc = get_top_hit_outputs(config)
if needs_qc:
    include: "qc/setup.snake"

outputs = config.setdefault('outputs',set())
logger.debug(config)

include: 'common/stats.snake'

# include bwa rules if any db is bwa
for db_info in config['dbs'].values():
    if re.search('bwa', db_info.get('format', "")):
        include: "annotation/bwa.snake"
        break

# include lastal rules if any db is lastdb
for db_info in config['dbs'].values():
    if re.search('last', db_info.get('format', "")):
        include: "annotation/lastal.snake"
        include: "common/fastq.snake"
        break

include: "common/transitions.snake"

if config.get('remove_rna', True) in ['True', True]:
    include: "qc/sort.rna.snake"
    include: "common/fastq.snake"
    ruleorder: filter_nonrrna_or_rrna > fastq_to_fasta

wildcard_constraints:
    search=r'vs\..+',
    alg=r'(dmnd[xp]|last[xnp]|blast[xnp]|sam)',
    top=r'(tophit|toporg)'

rule all:
    input: outputs

filter_params_patt=r'(?:_([a-zA-Z])(-?[0-9.]+))'
filter_params_rexp=re.compile(filter_params_patt)
rule filter_m8:
    input: '{file_root}.{alg}'
    output: '{file_root}.{alg}.{params}'
    wildcard_constraints:
        params=filter_params_patt + r'+'
    params:
        opts=lambda w: \
            " ".join(["-{} {}".format(o,v) \
                      for o,v in filter_params_rexp.findall(w.params)]),
        fmt=lambda w: 'blast' if re.search('last', w.alg) else w.alg,
    benchmark:
        'benchmarks/{file_root}.{alg}.filter.{params}.time'
    version:
        get_version('filter_blast_m8.py')
    shell:
        "filter_blast_m8.py {params.opts} -f {params.fmt} -o {output} {input}"

rule assign_top_hits:
    input:
        expand('{sample}.vs.{{db}}.{{alg}}.{{filter}}',
               sample=config['sample_data'])
    output:
        expand('{sample}.vs.{{db}}.{{alg}}.{{filter}}.{{top}}',
               sample=config['sample_data'])
    benchmark:
        'benchmarks/assign_top_hits.{db}.{alg}.{filter}.{top}.time'
    version:
        get_version('assign_top_hit.py')
    params:
        fmt=lambda w: 'blast' if re.search('last', w.alg) else w.alg,
    shell:
        "assign_top_hit.py -f {params.fmt} -C {wildcards.top} \
        -o .{wildcards.top} {input}"

rule count_hits:
    """ take a hit table and count hits to each hitid 
    
    if {rna} in the output file is not "all",
        use filtered version of the top hits
    if {rna} in the output file is "all":
        use the full top hits file (no suffix)
    """
    input:
        lambda w: '{sample}.{search}.{top}{rna}'.format(
            sample=w.sample,
            search=w.search,
            top=w.top,
            rna="" if w.rna == 'all' else '.' + w.rna,
        )
    output:
        '{sample}.{search}.{top}.{rna}.hitid.counts'
    benchmark:
        "benchmarks/{sample}.{search}.{top}.{rna}.count.time"
    log:
        "logs/{sample}.{search}.{top}.{rna}.count.log"
    version:
        get_version("count_hits.py")
    shell:
        "count_hits.py -v -i {input} -H 1 \
        > {output} 2> {log}"

rule filter_hits:
    """ remove rRNA reads from count table (only works for fastq input)"""
    input:
        hits='{sample}.{search}.{top}',
        nonrna=lambda w: get_rna_filtered_reads(w, config)
    output: '{sample}.{search}.{top}.{rna}'
    threads: 2
    benchmark: 'benchmarks/{sample}.{search}.{top}.{rna}.time'
    params:
        get_ids_cmd=lambda w: get_get_ids_cmd(w, config)
    shell: "screen_table.py {input.hits} -k \
             -l <({params.get_ids_cmd}) > {output}"

rule compile_hit_counts:
    """
    Uses pandas to outer join hit counts. The {rna} wildcard is 
    expected to be "non-rRNA", "SSU", "LSU",  or "all".
    """
    input:
        lambda w: expand('{sample}.{filter}.{top}.{rna}.hitid.counts',
                         filter=config['db_strings'][w.db],
                         top=w.top,
                         rna=w.rna,
                         sample=config['sample_data'])
    output:
        'counts.{db}.{top}.{rna}.hitids'
    params:
        input_map=lambda w: {s:'{sample}.{filter}.{top}.{rna}.hitid.counts'\
                                .format(sample=s,
                                        top=w.top,
                                        rna=w.rna,
                                        filter=config['db_strings'][w.db]) \
                             for s in config['sample_data']},
    benchmark:
        'benchmarks/counts.{db}.{top}.{rna}.hitidis.time'
    run:
        import pandas, re
        for sample, input_file in params.input_map.items():
            sample_counts = pandas.read_table(input_file, 
                                              index_col=0,
                                              names=[sample,])
            try:
                counts = counts.join(sample_counts, how='outer')
            except NameError:
                counts = sample_counts
        counts.to_csv(output[0], sep='\t')


