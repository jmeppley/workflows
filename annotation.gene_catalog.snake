"""
Python Makefile to create an anntotated gene catalog

Starting point:
   multiple assembled metagenomes (configured in configfile) 

Workflow:

 * collect all faa and fna annotations
 * pull out just coding sequences from fna files
 * cluster all nucl CDS at 95%
 * pull out faa version of cluster reps
 * query genes in configured databases: usu RefSeq, KEGG, COG, PFAM, and EGGnog
 * tabulate tax v gene_families counts
 * generate db specific annotations and merge into final table

The middle part of the workflow should be the same as the annotation.genes.snake workflow.
"""
# add my tools to the path (Somewhat of a hack, maybe I'll get my stuff in
# conda eventually)
include: "common/tool.path.snake"

import os
import glob
import re
import yaml
import pandas
from Bio import SeqIO
from python import gene_catalog
from python.common import get_version, apply_defaults, get_file_name 
from python.annotate import get_db_dot_fmt_strings

#########
# CONFIGURATION
#
# defaults for basic operation
# ranks to collect taxa on (defaults to order)
config.setdefault('clade_ranks', ['order'])

# assemblies located in paths
# listed in config[assembly_list] or file config[assembly_list_file]
if "assembly_list" not in config:
    with open(config['assembly_list_file']) as LIST:
        config['assembly_list'] = [l.strip() for l in LIST.readlines()]

# soma assemblies need to be renamed to fit in the big catalog
# listed in config as list of 2-entry dicts:
# assembly_renaming:
#   - assembly: /full/path/to/assembly
#     regex: "s/old_prefix/new_prefix/"
#   - assembly: . . .
# Change to a simple dict for use in makefile
assembly_renaming_map = {x['assembly']:x['regex'] \
                         for x in config.get('assembly_renaming', [])}

# software parameters
defaults = {
    'cdhit': {
        'threads': 20,
        'options': '-c 0.95 -M 1000000 -G 0 -aS 0.9 -g 1 -r 1 -d 0',
        'output_str': 'c.95.aS.9.g1.r1.G0',
    },
    'hmmer': {'threads': 2},
    'lastal': {'threads': 10},
}
apply_defaults(config, defaults)

# rules for gene annmotation workflow
include: "common/stats.snake"
include: "annotation/common.genes.snake"

# Define some trasitions to break the workflow up into segments
transitions = config.setdefault('transitions',{})
# the first part creates the clustered faa
transitions['all_genes.clustered.faa'] = \
            'all_genes.ffn.{}.faa'.format(config['cdhit']['output_str'])
# the clustered ffn is ambiguously named, so lets add ffn to the end
transitions['all_genes.ffn.{}.ffn'.format(config['cdhit']['output_str'])] = \
            'all_genes.ffn.{}'.format(config['cdhit']['output_str'])
# the second part will work from there (using the annotation.genes workflow)
prefix = 'all_genes.clustered'
# the last part will merge all the annotation files
gene_family_db_dot_fmts = get_db_dot_fmt_strings(gene_family_dbs, config, 'faa')
for dbdotfmt in gene_family_db_dot_fmts:
    db = dbdotfmt.split(".",1)[0]
    transitions['all_genes.clustered.annotations.{}'.format(db)] = \
            'all_genes.clustered.annot.gene_family.{}.tsv'.format(dbdotfmt)

# include transitions makefile only after all transitions defined
include: "common/transitions.snake"

# how to search against taxdb
config['taxdbfmt'] = config['dbs'][config['taxdb']].get('format','lastx')

# End configuration
##########

##########
# set up list of files to create
#  - The final tabulations
#  - Stats and histrogram files for fasta files
#  - The final annotation table
annotation_file_list = \
                expand("{prefix}.annot.{taxdb}.{taxdbfmt}.{clade_rank}.vs.{db_dot_fmt}.tsv",
                       prefix=prefix,
                       taxdbfmt=config['taxdbfmt'],
                       taxdb=config['taxdb'],
                       clade_rank=config['clade_ranks'],
                       db_dot_fmt=gene_family_db_dot_fmts,) + \
                expand("stats/{prefix}.{suffix}.{ext}", 
                       ext=['stats','hist'],
                       suffix=['faa','fna'],
                       prefix="all_genes") + \
                expand("stats/{prefix}.{suffix}.{ext}", 
                       ext=['stats','hist'],
                       suffix=['faa'],
                       prefix=prefix) + \
                [prefix + ".annotations.tab"]

logger.debug("Snakefile config:\n" + yaml.dump(config))

# The first target defines the files to be created 
#  (Counterintuitively, these are listed as the "input" of the rule
rule gene_annotation_all:
    input:
        annotation_file_list
#########

#########
# Helper functions
                                                   
def get_all_annotation_files(wildcards):
    """
    Find the contig.annotations.{wildcards.ext} for each assembly

    Replace file name with renamed file name if assembly needs 
    renaming
    """
    ext = wildcards.ext
    # hack for sliding in fixed gene calls
    path_prefix = config.setdefault('gene_path_prefix', '')
    gene_file_root = config.get('gene_file_root', 'contigs.annotations')
    if 'gene_path_prefix' in config and ext=='fna':
        ext='ffn'

    for assembly_path in config['assembly_list']:
        file_name = os.path.join(path_prefix + assembly_path, 
                                 '{}.{}'.format(gene_file_root, ext))

        if assembly_path in assembly_renaming_map:
            file_name = "renamed_dir" + file_name

        yield file_name

def get_assembly_coverage_files(wildcards):
    """
    Find all the contig.coverages.{sample}.txt for each assembly
    """
    for assembly_path in config['assembly_list']:
        for file_name in glob.glob(os.path.join(assembly_path,
                                'contigs.coverages.*.txt')):
            if assembly_path in assembly_renaming_map:
                file_name = "renamed_dir" + file_name
            yield file_name

def get_assembly_read_stats(wildcards):
    """
    Find all the cleaned reads stats files for each assembly
    """
    for assembly_path in config['assembly_list']:
        for file_name in glob.glob(os.path.join(assembly_path,
                                'stats',
                                'all_cleaned_reads.fastq.stats')):
            yield file_name

##########
# RULES:
#  This lays out the dependencies and logic of the workflow

## First we collect the genes and cluster them

rule rename_annotations:
    """ Renames contigs and genes in any annotation file that needs it """
    input: "{assembly}/{annotation_file}.{ext}"
    output: temp("renamed_dir{assembly}/{annotation_file}.{ext}")
    benchmark: 'benchmarks/rename_annotations{assembly}/{annotation_file}.{ext}.time'
    wildcard_constraints:
        ext='(faa|fna|ffn|txt)'
    params:
        regex=lambda w: assembly_renaming_map[re.sub('^' + \
                            config['gene_path_prefix'], '', \
                            w.assembly)]
    shell: "perl -pe '{params.regex}' \
            < {input} \
            > {output}"

rule collect_annotations:
    input: get_all_annotation_files
    output: "all_genes.{ext}"
    benchmark: 'benchmarks/all_genes.{ext}.time'
    wildcard_constraints:
        ext=r'(fna|faa)'
    shell:
        """
        cat {input} > {output}
        """

rule get_fasta_id_list:
    input: "{file_root}.{ext}"
    output: "{file_root}.{ext}.ids"
    benchmark: 'benchmarks/{file_root}.{ext}.ids.time'
    wildcard_constraints:
        ext=r'(fna|ffn|faa|fasta|fa)'
    shell:
        r"""
        grep "^>" {input} \
         | perl -pe 's/>(\S+)\s.+/\1/' \
         | sort \
         | uniq \
         > {output}
        """

rule filter_fna:
    input:
        "all_genes.faa.ids",
        "all_genes.fna"
    output: 
        "all_genes.ffn"
    benchmark: 'benchmarks/all_genes.ffn.time'
    shell: "screen_list.py -l {input[0]} -k {input[1]} > {output}"

rule cluster_ffn:
    input: "all_genes.ffn"
    output: "all_genes.ffn.{}".format(config['cdhit']['output_str'])
    benchmark: 'benchmarks/all_genes.ffn.{}.time' \
                        .format(config['cdhit']['output_str'])
    threads: config['cdhit']['threads']
    params:
        cd_hit_options=config['cdhit']['options']
    shell:
        "cd-hit-est -T {threads} {params.cd_hit_options} \
         -i {input} -o {output}"

rule get_cluster_rep_faa:
    input:
        "all_genes.ffn.{cd_hit_output_str}.ffn.ids",
        "all_genes.faa"
    output:
        "all_genes.ffn.{cd_hit_output_str}.faa"
    benchmark:
        "benchmarks/all_genes.ffn.{cd_hit_output_str}.faa.time"
    shell: "screen_list.py -l {input[0]} -k {input[1]} > {output}"

## We also need to collect the contig coverages
rule get_gene_coverages:
    input: 
        contig_covs=get_assembly_coverage_files,
        read_stats=get_assembly_read_stats,
        gene_list="all_genes.ffn.{}.ffn.ids" \
                        .format(config['cdhit']['output_str'])
    output: 'all_genes.clustered.coverage.tsv'
    benchmark: 'benchmarks/all_genes.clustered.coverage.tsv.time'
    run:
        # get map from contig name to genes
        contig_genes = {}
        contig_rexp = re.compile(r'_\d+$')
        with open(get_file_name(input.gene_list)) as GENES:
            for gene in GENES:
                gene = gene.strip()
                contig = contig_rexp.sub('', gene)
                contig_genes.setdefault(contig, []).append(gene)

        with open(get_file_name(output), 'wt') as OUT:
            for contig, coverage in gene_catalog.normalize_coverages(input):
                for gene in contig_genes.get(contig, []):
                    OUT.write('{}\t{}\n'.format(gene, coverage))

rule refseq_annotations:
    input:
        hits='all_genes.clustered.vs.RefSeq.lastp',
        db=config['dbs'][config['taxdb']]['path'] + ".prj"
    output: 'all_genes.clustered.annotations.RefSeq'
    benchmark: 'benchmarks/all_genes.clustered.annotations.RefSeq'
    params:
        db=config['dbs'][config['taxdb']]['path']
    run:
        a = gene_catalog.RefSeqGeneAnnotator(get_file_name(params.db))
        a.annotate_genes_rs_prot(get_file_name(input.hits), 
                                 get_file_name(output))

rule kegg_annotations:
    input:
        hits='all_genes.clustered.vs.KEGG.lastp',
        db=config['dbs']['KEGG']['path'] + '.prj'
    output: 'all_genes.clustered.annotations.KEGG'
    benchmark: 'benchmarks/all_genes.clustered.annotations.KEGG'
    params:
        db=config['dbs']['KEGG']['path']
    run:
        a = gene_catalog.KeggGeneAnnotator(get_file_name(params.db))
        a.annotate_genes_kg(get_file_name(input.hits), get_file_name(output))

rule final_table:
    input: expand('all_genes.clustered.annotations.{db}', \
                  db=config['dbs'])
    output: 'all_genes.clustered.annotations.tab'
    benchmark: 'benchmarks/all_genes.clustered.annotations.tab'
    run:
        # scan table file names so we can start with RefSeq
        db_file_map = {}
        ref_seq_table = None
        for table_file in input:
            db_name = re.search(r'annotations\.(.+)$', table_file)\
                        .group(1).strip()
            if re.search(r'^(RS|RefSeq)$', db_name, re.IGNORECASE):
                ref_seq_table = table_file
            else:
                db_file_map[db_name] = table_file

        # load RefSeq annotations
        annot = pandas.read_table(ref_seq_table, header=0, index_col=0)
        logger.debug("Annotation table shape is: {}".format(annot.shape))

        # iteratively join other annotations
        for db in sorted(db_file_map.keys()):
            table = pandas.read_table(db_file_map[db],
                                      index_col=0,
                                      header=0,
                                      names=['Gene', db])
            annot = annot.join(table, how='outer')
            logger.debug("Annotation table shape is: {}".format(annot.shape))

        # save table to output file
        annot.to_csv(get_file_name(output), sep='\t')

