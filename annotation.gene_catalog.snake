"""
Python Makefile to create an anntotated gene catalog

Starting point is either:
    1) existing gene catalog: faa file of protein gene sequences (already clustered)
    2) multiple assembled metagenomes (identified via the configfile) 

Workflow:

If starting from assemblies:
 * collect all faa and ffn annotations
 * pull out just coding sequences from ffn files
 * cluster all nucl CDS at 95%
 * pull out faa version of cluster reps

Annotations:
 * query genes in configured databases: usu RefSeq, KEGG, COG, PFAM, and EGGnog
 * tabulate tax v gene_families counts
 * generate db specific annotations and merge into final table

The initial annoation steps are the same as the annotation.genes.snake workflow.

The taxonomic db (eg /path/to/dbname) must have:
 * a two column tab separated map from hit id to taxid (/path/to/dbname.tax)
 * a two column tab separated map from hit id to description
    (/path/to/dbname.ids)
 * NCBI-style taxdump files (nodes.dmp and names.dmp in /path/to/)

If the taxonomic db name starts with "rs", "refseq", or "gtdb" (case insensitive),
protein functions are parsed from the header (.ids) table

"""
import os
import glob
import re
import yaml
import pandas
from Bio import SeqIO
from python import gene_catalog
from python.common import get_version, apply_defaults, get_file_name, TRUTH 
from python.annotate import get_db_dot_fmt_strings

#########
# CONFIGURATION
#
# defaults for basic operation
# ranks to collect taxa on (defaults to order)
include: "common/stats.snake"

config.setdefault('clade_ranks', ['order'])

# set some defaults
defaults = {
    'hmmer': {'threads': 2},
    'lastal': {'threads': 10},
}
apply_defaults(config, defaults)

# Define some trasitions to break the workflow up into segments
transitions = config.setdefault('transitions',{})

# do we do the full taxon/funtion cross tabulations?
run_cross_tab = config.get('cross_tab', False) in TRUTH

# if no gene catalog file given, try to build it from assemblies
GENE_CATALOG_KEY='genes_file'
prefix = 'all_genes.clustered'
if GENE_CATALOG_KEY not in config:
    # you'll need to configure an assembly_list
    include: 'annotation/build.gene_catalog.snake'
else:
    # symlink the genes in as a starting point
    prefix = config.get('naming_prefix', prefix)
    transitions[prefix + '.faa'] = config[GENE_CATALOG_KEY]

    # we can't calculate coverages, so look for config or create dummy
    local_coverage_file = '{}.coverage.tsv'.format(prefix)
    if run_cross_tab:
        if 'coverage_file' in config:
            coverage_file = config.get('coverage_file', local_coverage_file)
            if coverage_file != local_coverage_file:
                transitions[local_coverage_file] = coverage_file
        else:
            include: 'annotation/dummy.coverage.snake'

# rules for gene annotation workflow
include: "annotation/common.genes.snake"

# the annotaton will work from the clustered genes
# the last part will merge all the annotation files
gene_family_db_dot_fmts = get_db_dot_fmt_strings(gene_family_dbs, config, 'faa')
for dbdotfmt in gene_family_db_dot_fmts:
    db = dbdotfmt.split(".",1)[0]
    transitions['{}.annotations.{}'.format(prefix, db)] = \
            '{}.annot.gene_family.{}.tsv'.format(prefix, dbdotfmt)

# include transitions makefile only after all transitions defined
include: "common/transitions.snake"

# how to search against taxdbs
tax_db_dot_algs = \
    ['{}.{}'.format(d, config['dbs'][d].get('format', 'lastx')) \
     for d in config['taxdbs']]

# which taxdb to incorporate?
primary_tax_db = config.get('primary_tax_db', None)
if primary_tax_db is None:
    # default to first configured db
    primary_tax_db = config['taxdbs'][0]
else:
    if primary_tax_db not in config['taxdbs']:
        raise Exception(("The configured primary_tax_db ({}) is not " \
                         "configued as a taxnomic db ({})") \
                         .format(primary_tax_db, ", ".join(config['taxdbs'])))
#
# End configuration
##########

##########
# set up list of files to create
#  - The final tabulations
#  - Stats and histrogram files for fasta files
#  - The final annotation table
output_files = config.get('outputs', set())
# per-database annotation counts
if run_cross_tab:
    output_files.update(
        expand("{prefix}.annot.{tax_db_dot_alg}.{clade_rank}.vs.{db_dot_fmt}.tsv",
               prefix=prefix,
               tax_db_dot_alg=tax_db_dot_algs,
               clade_rank=config['clade_ranks'],
               db_dot_fmt=gene_family_db_dot_fmts,))
# gene catalog stats
output_files.update(
    expand("stats/{prefix}.{suffix}.{ext}", 
           ext=['stats','hist'],
           suffix=['faa'],
           prefix=prefix))
# final annotations
output_files.add(prefix + ".annotations.tab")

# debugging
logger.debug("Snakefile config:\n" + yaml.dump(config))

# The first target defines the files to be created 
#  (Counterintuitively, these are listed as the "input" of the rule
rule gene_annotation_all:
    input:
        output_files
#########

##########
# RULES:
#  This lays out the dependencies and logic of the workflow

# TODO: generalize for GTDB
rule taxdb_annotations:
    input:
        hits='{}.vs.{{taxdb}}.lastp'.format(prefix),
        db=lambda w: config['dbs'][w.taxdb]['path'] + ".prj",
        ids=lambda w: config['dbs'][w.taxdb]['path'] + ".ids"
    output: '{}.annotations.{{taxdb}}'.format(prefix)
    benchmark: 'benchmarks/{}.annotations.{{taxdb}}'.format(prefix)
    params:
        db=lambda w: config['dbs'][w.taxdb]['path']
    run:
        a = gene_catalog.TaxDBGeneAnnotator(get_file_name(params.db))
        if wildcards.taxdb.lower().startswith('rs') or \
           wildcards.taxdb.lower().startswith('refseq'):
            db_type = gene_catalog.REFSEQ
        elif wildcards.taxdb.lower().startswith('gtdb'):
            db_type = gene_catalog.GTDB
        else:
            db_type = None
        a.annotate_genes_rs_prot(get_file_name(input.hits), 
                                 get_file_name(output),
                                 db_type=db_type,
                                )

rule kegg_annotations:
    input:
        hits='{}.vs.KEGG.lastp'.format(prefix),
        db=config['dbs']['KEGG']['path'] + '.prj',
        ids=config['dbs']['KEGG']['path'] + ".ids"
    output: '{}.annotations.KEGG'.format(prefix)
    benchmark: 'benchmarks/{}.annotations.KEGG'.format(prefix)
    params:
        db=config['dbs']['KEGG']['path']
    run:
        a = gene_catalog.KeggGeneAnnotator(get_file_name(params.db))
        a.annotate_genes_kg(get_file_name(input.hits), get_file_name(output))

def collapse_duplicates(table, col='Gene', sep=','):
    """ aggregate on given column by simply concatenating around the given
    separator """
    return table.groupby(col).agg(lambda S: sep.join(str(v) for v in S))

rule final_table:
    """
    The collated annotations. Although we might want to run multiple TAX DBs
    putting them all into one annotation table would make a huge file.
    """

    input:
        tax_db='{prefix}.annotations.{db}'.format(prefix=prefix, \
                                                  db=primary_tax_db),
        func_dbs=expand('{prefix}.annotations.{db}', \
                        prefix=prefix, \
                        db=gene_family_dbs),
    output: '{}.annotations.tab'.format(prefix)
    benchmark: 'benchmarks/{}.annotations.tab'.format(prefix)
    run:
        print("Running")

        # load Taxonomic annotations (refseq or GTDB)
        annot = pandas.read_csv(input.tax_db, sep='\t', header=0, index_col=0)
        print(annot.shape)
        logger.info("Annotation table shape is: {}".format(annot.shape))

        # load functional annotations (gene families like KEGG or PFAM)
        for func_annot_table in input.func_dbs:
            print(repr(func_annot_table))
            # these should be two column maps from gene ids to gene family ids
            db_name = func_annot_table.split(".")[-1]
            print(db_name)
            # name data column after db
            table = pandas.read_csv(func_annot_table, sep='\t',
                                      index_col=None,
                                      header=0,
                                      names=['Gene', db_name])
            print(table.shape)
            # if there are duplicate entries Cfor some genes, separate by
            # semicolon
            table = collapse_duplicates(table, col='Gene', sep=';')
            print(table.shape)

            # merge with existing annotations (add as new column)
            annot = annot.join(table, how='outer')
            print("Annotation table shape is: {}".format(annot.shape))

        # save table to output file
        annot.to_csv(get_file_name(output), sep='\t')
