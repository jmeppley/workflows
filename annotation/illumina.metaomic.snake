"""
Snakefile to clean and join illumina reads for read-based analysis

We are starting with the old recipe from illuminaPrep:
 * trimmomatic to remove primers
 * pandaseq to join and screen
 * trimmomatic again to trim ends and windows
"""
import os
import sys

snakefile_path=os.path.dirname(os.path.abspath(workflow.main_snakefile))
sys.path[0]=os.path.join(snakefile_path,'..','python')
from common import get_version, parse_stats
from annotate import get_db_dot_fmt_strings, get_last_alg

####
# INCLUDES and CONFIG
#
if 'samples' not in config or 'dbs' not in config:
    raise Exception("You need to supply sample source files and annotation dbs to proceed. Check out the example YAML files")
# illumina cleaning
# this should read sample list and data from illumina.yaml
include: "../qc/clean.illumina.snake"
#
# do a single sample in this dir
sample_prefix_list = [config['sample_id']]
#
# split out rRNA
include: "../qc/sort.rna.snake"
#
# get read anotation workflow to annotate non rRNA reads
# set the annotation prefixes...
config['annotation_prefixes']=\
        expand("{sample}_reads.clipped.joined.trimmed.non-rRNA",
               sample=sample_prefix_list)
#
# This prefix will cause the necessary cleaning to happen
clean_prefixes = expand("{sample}_reads.clipped.joined.trimmed",
                        sample=sample_prefix_list)
include: "../annotation/silva.snake"
#
# get special list for building file names
gene_family_db_dot_fmts = get_db_dot_fmt_strings(gene_family_dbs,
                                                 config,
                                                 'fasta')

annot_tabs = []
tax_counts = []
for taxdb in config['taxdbs']:
    taxalg = get_last_alg(config['dbs'][taxdb].get('format','lastp'),
                          'fasta')
    annot_tabs.extend(
        expand("{prefix}.annot.{taxdb}.{taxalg}.{clade}.vs.{db_dot_fmt}.tsv",
               taxdb=taxdb,
               taxalg=taxalg,
               db_dot_fmt=gene_family_db_dot_fmts,
               prefix=config['annotation_prefixes'],
               clade=config['clade_ranks']))
    tax_counts.extend(
        expand("{prefix}.nocolon.annot.{taxdb}.{taxalg}.{clade}.count.tsv",
               prefix=config['annotation_prefixes'],
               taxdb=taxdb,
               taxalg=taxalg,
               clade=config['clade_ranks']))
#
####

ruleorder: remove_colons > fastq_to_fasta

rule report_all:
    """
    This rule is both the "all" target that defines what to do,
    and it generates a final report that should give a useful summary 
    of the results and make apparent any massive failures in processing
    """
    input:
        # from clean.illumina.snake
        clean_stats=[f for f in reads_stats_files if re.search(r'\.stats$',f)],
        clean_hists=[f for f in reads_stats_files if re.search(r'\.hist$',f)],
        # from common.sixframe.snake
        annot_stats=expand("{prefix}.{type}.stats",
                           prefix=config['annotation_prefixes'], 
                           type=['fasta','sixframe.faa']),
        annot_hists=expand("{prefix}.{type}.hist",
                           prefix=config['annotation_prefixes'], 
                           type=['fasta','sixframe.faa']),
        annot_tabs=annot_tabs,
        tax_counts=tax_counts,
        # rrna counts
        rrna_counts=\
            expand("{prefix}.rRNA.annot.{db_dot_fmt}.{rank}.count.tsv",
                prefix=clean_prefixes,
                rank=config['clade_ranks'],
                db_dot_fmt=['{}.{}'.format(d,a) for d,a in silva_fmts.items()]),
        rrna_stats=expand("{prefix}.{type}.fastq.{ext}",
                prefix=clean_prefixes,
                ext=['stats',],
                type=['rRNA','non-rRNA']),
        rrna_hists=expand("{prefix}.{type}.fastq.{ext}",
                prefix=clean_prefixes,
                ext=['hist',],
                type=['rRNA','non-rRNA'])
    output:
        "{sample}_reads.annot.report".format(sample=config['sample_id'])
    run:
        import pandas, re
        with open(output[0],'w') as OUT:
            # cleaned read counts (step by step)
            OUT.write("== Read ==\nstep\treads\tbases\n")
            stats_files = sorted(input.clean_stats, 
                                 key=lambda f: os.stat(f).st_mtime) + \
                          sorted(input.rrna_stats, 
                                 key=lambda f: os.stat(f).st_mtime) + \
                          sorted(input.annot_stats, 
                                 key=lambda f: os.stat(f).st_mtime)
            for input_file in stats_files:
                stats = parse_stats(input_file)
                stats['step']=re.sub(r'^{}_reads\.'.format(config['sample_id']),
                                     '',
                                     re.sub(r'\.f[a-z](\.gz)?\.stats$',
                                            '',
                                            input_file))
                OUT.write("{step}\t{reads}\t{bases}\n".format(**stats))
            OUT.write("//\n")

            # flag any empty histograms
            for input_file in input.clean_hists + \
                    input.rrna_hists + \
                    input.annot_hists:
                if os.stat(input_file).st_size==0:
                    OUT.write("WARNING: empty histogram: {}\n"\
                                .format(input_file))
            OUT.write('\n')

            # check Silva counts
            OUT.write("== Taxon counts found by rank in Silva ==\n")
            OUT.write("Silva DB\trank\ttaxon count\tread count\n")
            for input_file in input.rrna_counts:
                db, rank = re.search(r'annot\.Silva([LS]SU)\.sam\.([a-z]+)\.count\.tsv', input_file).groups()
                read_counts = pandas.read_table(input_file,
                                                header=None, 
                                                index_col=0, 
                                                names=['read_count'])\
                                .read_count
                taxon_count = int(read_counts.count())
                read_count = int(read_counts.sum())
                OUT.write("{db}\t{rank}\t{taxon_count}\t{read_count}\n"\
                           .format(**vars()))
            OUT.write("//\n\n")

            # check lastx tax counts
            OUT.write("== Taxon counts found by rank in RefSeq (lastx) ==\n")
            OUT.write("rank\ttaxon count\tread count\n")
            for input_file in input.tax_counts:
                rank = re.search(r'\.last[nx]\.([a-z]+)\.count\.tsv', input_file).group(1)
                read_counts = pandas.read_table(input_file,
                                                header=None, 
                                                index_col=0, 
                                                names=['read_count'])\
                                .read_count
                taxon_count = int(read_counts.count())
                read_count = int(read_counts.sum())
                OUT.write("{rank}\t{taxon_count}\t{read_count}\n"\
                           .format(**vars()))
            OUT.write("//\n\n")

            # check gene counts
            OUT.write("== Read counts by gene and taxon ==\n")
            OUT.write("table\ttaxa\tgenes\treads\n")
            for input_file in input.annot_tabs:
                counts = pandas.read_table(input_file,
                                           header=0,
                                           names=['taxon','gene','count'])
                name = re.search(r'non-rRNA\.annot\.(.+)\.tsv$',
                                 input_file).group(1)
                taxon_counts = counts.groupby('taxon').sum()
                taxon_count = int(taxon_counts.count())
                read_count = int(taxon_counts.sum())
                gene_count = int(counts.groupby('gene').sum().count())
                OUT.write('{}\t{}\t{}\t{}\n'.format(name,
                                                    taxon_count,
                                                    gene_count,
                                                    read_count))
            OUT.write("//\n")

rule dummy_reads:
    """
    create link to non rrna reads so that we can do lastx annotations in parallel with different naming prefix

    NOTE: this hack is relying on the count_tax_hits rule from silva.snake
    """
    input: "{prefix}_reads.clipped.joined.trimmed.non-rRNA.fastq"
    output: temp("{prefix}_reads.cleaned.non-rRNA.fastq")
    shell: "ln -s {input} {output}"
