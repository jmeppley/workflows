import os, sys, re, glob, pandas, itertools,  yaml
from snakemake import logger

data_dir = config.setdefault('data_dir', '..')

# find all the MG genomes
mg_genome_fasta_files = glob.glob(data_dir + "/*/*/*/contigs.fasta")
mg_genomes = {}
mg_bams = {}
mg_cleaned_reads = {}
mg_renames = {}
for fasta_file in mg_genome_fasta_files:
    rundate, sample = \
        re.search(r'/(\d\d\d\d\d\d)[_-]NS500.+/([^/]+)/contigs.fasta', \
                  fasta_file).groups()
    sample_name = sample + "-" + rundate
    mg_genomes[sample_name] = fasta_file
    mg_bams[sample_name] = glob.glob(re.sub(r'contigs.fasta','mapping/*.reads.vs.contigs.bam',fasta_file))
    cleaned_reads = glob.glob(re.sub(r'contigs.fasta', "*.dropse.fastq", fasta_file))
    if len(cleaned_reads)==1:
        mg_cleaned_reads[sample_name] = cleaned_reads[0]
    else:
        mg_cleaned_reads[sample_name] = 'no_such_file'
    mg_renames[sample_name] = glob.glob(re.sub(r'contigs.fasta','*.renamed.R1.tsv',fasta_file))

mgs_by_depth = {}
for mg in mg_genomes:
    mgs_by_depth.setdefault(re.search(r'(\d+)-\d+$', mg).group(1), []).append(mg)

# find all the SAG genomes
sag_genome_fasta_files = glob.glob(data_dir + "/*/IMG*/*assembled.fna")
sag_genomes = {re.search(r'\[([^\]]+)\]/', f).group(1):f for f in sag_genome_fasta_files}
sag_fastq_tarballs = glob.glob(data_dir + "/*/QC_and*/*fastq.gz")
sag_reads = {re.search(r'\[([^\]]+)\]/', t).group(1):t for t in sag_fastq_tarballs}

logger.debug(yaml.dump(config))
logger.debug("MG GENOMES: " + yaml.dump(mg_genomes))
logger.debug("MG READS: " + yaml.dump(mg_cleaned_reads))

# Define the final outputs
sag_reads_outputs = expand('{sag}/reads.fastq', sag=sag_reads)
logger.debug('SAGREADS: ' + repr(sag_reads_outputs) + "\n")
mg_reads_outputs = expand('{sag}/matching_reads_from_mg.{mg}.fastq', \
                          sag=sag_genomes, mg=mg_bams)
logger.debug('MGREADS: ' + repr(mg_reads_outputs) + "\n")
reads_by_depth_outputs = \
        expand('{sag}/matching_reads_from_depth.{depth}.fastq', \
                     sag=sag_genomes, depth=[d for d,ms in mgs_by_depth.items() if len(ms)>1])
logger.debug("READSBYDEPTH: " + repr(reads_by_depth_outputs) + "\n")
contig_outputs = expand('{sag}/matching_contigs_from_all_mgs.fna', sag=sag_genomes)
logger.debug("CONTIG OUTPUTS: " + repr(contig_outputs) + "\n\n")

rule output:
    input:
        sag_reads=sag_reads_outputs,
        mg_reads=mg_reads_outputs,
        depth_reads=reads_by_depth_outputs,
        contigs=contig_outputs

rule list_matching_contigs:
    input: '{sag}/matching_contigs_from_mg.{mg}.lastal'
    output: '{sag}/matching_contigs_from_mg.{mg}.list'
    shell: 'filter_blast_m8.py -f blast --nonoverlapping -B 1000 {input} | cut -f 2 > {output}'

rule lastdb:
    input: '{fasta}'
    output: '{fasta}.prj'
    shell: 'lastdb -v {wildcards.fasta} {wildcards.fasta}'

rule find_matching_contigs:
    input:
        fasta=lambda w: sag_genomes[w.sag],
        db=lambda w:'{}.prj'.format(mg_genomes[w.mg])
    output:
        '{sag}/matching_contigs_from_mg.{mg}.lastal'
    params:
        db=lambda w: mg_genomes[w.mg]
    threads:
        config.get('lastal_threads', 10)
    shell:
        'lastal -P {threads} -F BlastTab {params.db} {input.fasta} > {output}'

rule matching_contigs_bed:
    input: 
        list='{sag}/matching_contigs_from_mg.{mg}.list',
        fasta=lambda w: mg_genomes[w.mg]
    output: '{sag}/matching_contigs_from_mg.{mg}.bed'
    threads: 2
    shell: "grep '^>' {input.fasta} | perl -pe 's/^>(\\S+)\\s.+length_(\\d+)_.+/\\1\\t1\\t\\2/' | screen_table.py -l {input.list} -k  > {output}"

rule matching_contigs_fna:
    input:
        list='{sag}/matching_contigs_from_mg.{mg}.list',
        fna=lambda w: mg_genomes[w.mg]
    output: '{sag}/matching_contigs_from_mg.{mg}.fna'
    shell: 'screen_list.py {input.fna} -l {input.list} -k -o {output}'

rule all_mg_contigs_for_sag:
    input: lambda w: \
        expand('{sag}/matching_contigs_from_mg.{mg}.fna', mg=mg_genomes, sag=w.sag)
    output: '{sag}/matching_contigs_from_all_mgs.fna'
    shell: 'cat {input} > {output}'

rule sam_header_only:
    input: '{some_file}.bam'
    output: '{some_file}.bam.header'
    shell: 'samtools view -H {input} > {output}'

rule mg_read_list_for_sag:
    input:
        bams=lambda w: mg_bams[w.mg],
        bed='{sag}/matching_contigs_from_mg.{mg}.bed'
    output: '{sag}/matching_reads_from_mg.{mg}.list'
    shell:
        """
        rm -f {output}
        for BAM in {input.bams}; do
            samtools view -L {input.bed} $BAM | cut -f 1 >> {output}
        done
        """

rule mg_reads_for_sag_17:
    """
    USes screen table (will match multiple reads with same name) to pull out
    SAM lines.

    Takes advantage of BWA output using only the 4 and 16 flags in the second column
    so that the sourted output will alwaus put fwd before rev reads.
    """
    input:
        bams=lambda w: mg_bams[w.mg17],
        reads='{sag}/matching_reads_from_mg.{mg17}.list'
    output: '{sag}/matching_reads_from_mg.{mg17}.fastq'
    wildcard_constraints:
        mg17='S.+170703'
    params:
        stmp=config.get('stmp', '/mnt/stmp' if os.path.exists('/mnt/stmp') else '/tmp')
    threads: 4
    shell:
        r"""
        rm -f {output}
        for BAM in {input.bams}; do
            samtools view $BAM | screen_table.py -l {input.reads} | cut -f 1,8,9 | sort -T {params.stmp} | perl -lane 'print "\@$F[0]\n$F[9]\n+\n$F[10]";' >> {output}
        done
        """

rule mg_reads_for_sag_16:
    """
    Goes back to raw reads using read list.
    
    I can't use screen_list, because it won't get pairs
    """
    input:
        fastq=lambda w: mg_cleaned_reads[w.mg16],
        renames=lambda w: mg_renames[w.mg16],
        read_list='{sag}/matching_reads_from_mg.{mg16}.list'
    output: '{sag}/matching_reads_from_mg.{mg16}.fastq'
    wildcard_constraints:
        mg16=r'H.+16\d+'
    run:
        with open(input.read_list) as R:
            read_list = set(r.strip() for r in R)

        # just cover the bases and add all versions of the read names
        renames = input.renames if isinstance(input.renames, list) else [input.renames,]
        for rename in renames:
            with open(rename) as M:
                for line in M:
                    old, new = line.strip().split()
                    if old in read_list or new in read_list:
                        read_list.add(new) 
                        read_list.add(old)

        logger.debug("Loaded list of {} reads including '{}'".format(
                        len(read_list),
                        next(iter(read_list))
                        ))

        read_rexp = re.compile(r'^@(\S+)\s')
        with open(output[0], 'wt') as OUT:
            with open(input.fastq) as F:
                try:
                    while True:
                        # reads are paired, so process in groups of 8 lines
                        lines = [next(F) for i in range(8)]
                        read_name = read_rexp.match(lines[0]).group(1)
                        if read_name in read_list:
                            for line in lines:
                                OUT.write(line)
                except StopIteration:
                    pass

rule reads_by_depth:
    input: lambda w: expand('{sag}/matching_reads_from_mg.{mg}.fastq', mg=mgs_by_depth[w.depth], sag=w.sag)
    output: '{sag}/matching_reads_from_depth.{depth}.fastq'
    shell: 'cat {input} > {output}'

rule sag_reads:
    input: lambda w: sag_reads[w.sag]
    output: '{sag}/reads.fastq'
    shell: 'gunzip -c {input} > {output}'

rule all_mg_reads_for_sag:
    input:
        expand('{{sag}}/matching_reads_from_mg.{mg}.fastq', mg=mg_genomes)
    output: '{sag}/matching_reads_from_all_mgs.fastq'
    shell: 'cat {input} > {output}'
