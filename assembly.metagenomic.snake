"""
Workflow for assembling metagenomic samples

 * renames reads to sample name(s)
 * cleans with:
   - bbduk (adapters)
   - bfc (error correction)
   - trimmomatic (quality and length)
 * runs assembler (SPAdes or megahit)
 * renames contigs
    (to config[assembly_name], if given)
    (to sample name, if only one)
 * annotates (rRNAs, tRNA, genes)

####
# Required conda packages:
#
# snakemake bbmap infernal spades prodigal pandas biopython bfc (optional)
###

see test/data/configs/spades.yaml for an example configuration

"""
import os, re, sys, glob, yaml, pandas, subprocess, tempfile
from Bio import SeqIO, __version__ as BIOPYTHON_VERSION

# add pymg to path
include: "common/tool.path.snake"

from python.common import get_version, parse_stats
from python.qc import setup_qc_outputs
from python.assembly import get_contig_length_summary_stats

# Initialize transitions
config.setdefault('transitions', {})

##
# Bring in components
#
# for mapping reads back to contigs
include: "common/mapping_bwa.snake"
#
## set up any QC
# don't separate rRNA
config.setdefault('remove_rna', False)
# use the assembly cleaning protocol
config.setdefault('cleaning_protocol', 'assembly')
outputs = config.setdefault('outputs',set())
cleaned_reads = setup_qc_outputs(config)
#outputs.update(cleaned_reads)
include: "qc/setup.snake"
include: "common/gunzip.snake"
#
# the assembler (add link from assembled contigs to ./contigs.raw.fasta)
assembler = config.get('assembler', 'spades')
if assembler == 'spades':
    include: "assembly/metagenomic.spades.snake"
    config['transitions']['contigs.raw.fasta'] = 'spades/contigs.fasta'
elif assembler == 'megahit':
    include: "assembly/metagenomic.megahit.snake"
    config['transitions']['contigs.raw.fasta'] = \
                    "megahit-{params}/megahit.contigs.fa" \
                                .format(params=config['megahit']['preset'])
else:
    raise Excption("Unknown assembler: " + config['assembler'])
#
# contig annotation (RNA, genes, coverage, stats)
include: "assembly/contig.annotation.snake"
#
# rule to create links
include: "common/transitions.snake"
include: "common/stats.snake"

# 
# Make sure assembly has name
if 'assembly_name' not in config:
    # if there is only one sample, use that
    sample_names = [sample \
                         for sample,data in config['sample_data'].items() \
                         if 'clean' in data]
    if len(sample_names)==1:
        config['assembly_name'] = sample_names[0]
    else:
        raise Exception("Please supply a naming string for this assembly "
                        "in config[assembly_name].")

logger.debug("Snakefile config:\n" + yaml.dump(config))

############
# RULES
#
# Start with the final product(s):
rule all:
    input:
        config['outputs'],
        "contigs.report",

rule contigs_fasta:
    """
    Renames the contigs from whatever the assembler outputs 
    to names based on config[assembly_name]

    The outputs is contigs.fasta, the root of all the annotation rules.
    """
    input:
        "contigs.raw.fasta"
    output:
        "contigs.all.fasta"
    log:
        "logs/contigs.fasta.link.log"
    benchmark:
        "benchmarks/contigs.rename.time"
    version:
        "biopython-{}".format(BIOPYTHON_VERSION)
    run:
        root_name = config['assembly_name']
        logger.debug("root name: {}".format(root_name))
        with open(input[0]) as INPUT:
            with open(output[0], 'w') as OUTPUT:
                for i, (title, sequence) \
                    in enumerate(SeqIO.FastaIO.SimpleFastaParser(INPUT)):
                        contig_name = "%s_c%d" % (root_name, i+1)
                        OUTPUT.write(">%s %s\n%s\n" % (contig_name,
                                                       title,
                                                       sequence))
                logger.debug("renamed {} contigs".format(i))

def get_read_files(reads_types, config):
    """
    code to get all the reads files for all samples

    This is needed so the final report can indicate how many reads went into
    the assembly.
    """
    # support either list of types or single type string (usu clean or raw)
    if isinstance(reads_types, str):
        reads_types = [reads_types,]

    # get sample_data for each sample
    for sample, sample_data in config['sample_data'].items():
        # only process types that exist in data for this sample
        for reads_type in set(reads_types).intersection(sample_data.keys()):
            reads_files = sample_data[reads_type]
            if isinstance(reads_files, str):
                yield reads_files
            else:
                for reads_file in reads_files:
                    yield reads_file

contig_cutoffs=[0, 500, 2000]
report_metrics=['Length', 'GC', 'ReadCount', 'MeanCov']
rule final_report:
    input:
        read_stats=['stats/{}.stats'.format(reads_file) \
                    for reads_file \
                    in get_read_files(['raw','clean'], config)],
        ssu_rrnas="contigs.vs.rRNA.cmsearch.SSU.gt1200.tsv",
        lsu_rrnas="contigs.vs.rRNA.cmsearch.LSU.gt2000.tsv",
        gene_stats="stats/contigs.annotations.faa.stats",
        contig_stats="contigs.final.stats.txt",
        histograms=expand("histograms/contigs_gt_{cutoff}/{metric}.hist", \
                          cutoff=contig_cutoffs, \
                          metric=report_metrics)
    output:
        "contigs.report"
    run:
        read_stats={}

        # paired reads
        total_clean_reads = 0
        for sample, sample_data in config['sample_data'].items():
            for reads_type in ['raw', 'clean']:
                if reads_type not in sample_data:
                    continue
                reads_files = sample_data[reads_type]
                if isinstance(reads_files, str):
                    reads_files = [reads_files,]
                for reads_file in reads_files:
                    stats_file = "stats/{}.stats".format(reads_file)
                    stats = parse_stats(stats_file)
                    match = re.search(r'R[12]', stats_file)
                    if match:
                        key_pref = sample + " " + reads_type + " " + match.group()
                    else:
                        key_pref = sample + " " + reads_type
            
                    read_stats['{} reads'.format(key_pref)]=stats['reads']
                    read_stats['{} bases'.format(key_pref)]=stats['bases']
                    
                    if reads_type=='clean':
                        total_clean_reads += stats['reads']

        # contigs (count, bases, N50)
        stats_table = pandas.read_table(get_file_name(input.contig_stats),
                        index_col=0)
        contig_stats = get_contig_length_summary_stats(stats_table,
                                                       N_levels=[50, 75, 90])

        contig_stats['GC'] = float(stats_table.GC.mean())
        contig_stats['mapped reads'] = int(stats_table.ReadCount.sum())
        contig_stats['mapped fraction'] = float(stats_table.ReadCount.sum() / \
                                                (2*total_clean_reads))

        # annotations
        stats = parse_stats(input.gene_stats)
        contig_stats['genes']=stats['reads']

        # full length SSUs
        ssu_count=-1
        with open(input.ssu_rrnas) as INF:
            for line in INF:
                ssu_count+=1
        contig_stats['SSUs']=ssu_count

        # full length LSUs
        lsu_count=-1
        with open(input.lsu_rrnas) as INF:
            for line in INF:
                lsu_count+=1
        contig_stats['LSUs']=lsu_count

        report={"reads":read_stats,"assembly":contig_stats}
        with open(output[0],'w') as OUTF:
            OUTF.write(yaml.dump(report, default_flow_style=False))

            OUTF.write("\n\n################\nHISTOGRAMS\n################\n")
            for hist_file in sorted(input.histograms):
                OUTF.write('\n')
                with open(hist_file) as INF:
                    OUTF.write(''.join(INF.readlines()))

