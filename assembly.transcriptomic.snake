"""
Workflow for assembling transcriptomic samples

 * renames reads to sample names
 * optionally cleans with:
   - bbduk (adapters)
   - bfc (error correction)
   - trimmomatic (quality and length)
 * runs assembler (SPAdes only, for now)
 * renames transcripts
    (to config[assembly_name], if given)
    (to sample name, if only one)
 * separates into rRNA and transcripts

####
# Required conda packages:
#
# snakemake bbmap infernal spades prodigal pandas biopython bfc (optional)
###

see test/data/configs/spades.yaml for an example configuration

"""
import os, re, sys, glob, yaml, pandas, subprocess, tempfile
from Bio import SeqIO, __version__ as BIOPYTHON_VERSION
from python.common import get_version, parse_stats, get_file_name
from python.qc import setup_qc_outputs


# add pymg to path
#puts stuff in tools into execution path
include: "common/tool.path.snake"

# Initialize transitions
#creating empty dictionary for updating paths/ names
# creates a symbolic link from one location to another
# if raw read files are somewhere else, this updates file path
config.setdefault('transitions', {})

##
# Bring in components
include: "common/stats.snake"

#
## set up any QC
# don't separate rRNA in reads
config.setdefault('remove_rna', False)

# use the assembly cleaning protocol
config.setdefault('cleaning_protocol', 'assembly')
outputs = config.setdefault('outputs',set())
cleaned_reads = setup_qc_outputs(config)

#outputs.update(cleaned_reads)
# use assembly cleanup defaults
include: "qc/setup.snake"

#
# the assembler (add link from assembled contigs to ./contigs.raw.fasta)
assembler = config.get('assembler', 'spades')
if assembler == 'spades':
    include: "assembly/metagenomic.spades.snake"
    config['transitions']['contigs.raw.fasta'] = 'spades/transcripts.fasta' #directory name
elif assembler == 'megahit':
    raise Excption("Unsupported RNA assembler: " + config['assembler'])
else:
    raise Excption("Unknown assembler: " + config['assembler'])
#
# separate rRNA from transcripts at end
include: "qc/sort.rna.snake"
for seqtype in ['non-rRNA', 'rRNA-only']:
    for extension in ['stats', 'hist']:
        outputs.add('stats/contigs.{}.fasta.{}'.format(seqtype, extension))
#
# contig annotation (RNA, genes, coverage, stats)
transcript_mapper = config.setdefault('transcript_mapper','salmon')
if transcript_mapper == 'salmon':
    include: "annotation/salmon.snake"
elif transcript_mapper == 'bwa':
    include: "common/mapping_bwa.snake"
else:
    raise Exception("Unknown transcript mapping tool: {}! Please check your configuration.".format(transcript_mapper))

include: "assembly/rrna.annotation.snake"

# rule to create links
# makes all the transition that we defined into actual rules
include: "common/transitions.snake"

# make sure tanstion source files don't get deleted
# stops temps() from deleting
from snakemake.io import flag
for file_name in list(config['outputs']) + list(config['transitions'].values()):
    flag(file_name, "temp", False)

# 
# Make sure assembly has name
# define naming root for contigs, may raise exception , need to define assembly name in config.yml
if 'assembly_name' not in config:
    # if there is only one sample, use that
    sample_names = [sample \
                         for sample,data in config['sample_data'].items() \
                         if 'clean' in data]
    if len(sample_names)==1:
        config['assembly_name'] = sample_names[0]
    else:
        raise Exception("Please supply a naming string for this assembly "
                        "in config[assembly_name].")

# rule to create rrna assembly data in the annotation makefile. Triggers SSU coverage to be run.
config['outputs'].add("assembly.{assembly_name}.report".format(**config))

logger.debug("Snakefile config:\n" + yaml.dump(config))

############
# RULES
#
# Start with the final product(s):
rule all:
    input:
    	# sets all outputs as target
        config['outputs'],

rule contigs_fasta:
    """
    Rename contigs to include assembly name that was specified
    """
    input:
        "contigs.raw.fasta"
    output:
        "contigs.fasta"
    log:
        "logs/contigs.fasta.link.log"
    benchmark:
        "benchmarks/contigs.fasta.txt"
    version:
        "biopython-{}".format(BIOPYTHON_VERSION)
    run:
        root_name = config['assembly_name']
        with open(input[0]) as INPUT:
            with open(output[0], 'w') as OUTPUT:
                for i, (title, sequence) \
                    in enumerate(SeqIO.FastaIO.SimpleFastaParser(INPUT)):
                        contig_name = "%s_c%d" % (root_name, i+1)
                        OUTPUT.write(">%s %s\n%s\n" % (contig_name,
                                                       title,
                                                       sequence))

def get_read_files(reads_type, config):
    for sample, sample_data in config['sample_data'].items():
        if reads_type in sample_data:
            reads_files = sample_data[reads_type]
            if isinstance(reads_files, str):
                yield reads_files
            else:
                for reads_file in reads_files:
                    yield reads_file

rule final_report:
#counts reads and contigs
    input:
        raw_stats=['stats/{}.stats'.format(reads_file) \
                   for reads_file in get_read_files('raw', config)],
        cleaned_stats=['stats/{}.stats'.format(reads_file) \
                   for reads_file in get_read_files('clean', config)],
        ssu_rrnas="contigs.vs.rRNA.cmsearch.SSU.gt{length}.tsv"\
                            .format(length=config.get('long_ssu_length',1200)),
        lsu_rrnas="contigs.vs.rRNA.cmsearch.LSU.gt{length}.tsv"\
                            .format(length=config.get('long_lsu_length',2000)),
        contig_stats="stats/contigs.fasta.stats",
    output:
        "assembly.{assembly_name}.report"
    run:
        read_stats={}

        # paired reads
        for sample, sample_data in config['sample_data'].items():
            #for reads_type in ['clean']:
            for reads_type in ['raw', 'clean']:
                if reads_type not in sample_data:
                    continue
                reads_files = sample_data[reads_type]
                if isinstance(reads_files, str):
                    reads_files = [reads_files,]
                for reads_file in reads_files:
                    stats_file = "stats/{}.stats".format(reads_file)
                    stats = parse_stats(stats_file)
                    match = re.search(r'R[12]', stats_file)
                    if match:
                        key_pref = sample + " " + reads_type + " " + match.group()
                    else:
                        key_pref = sample + " " + reads_type
            
                    read_stats['{} reads'.format(key_pref)]=stats['reads']
                    read_stats['{} bases'.format(key_pref)]=stats['bases']

        # contigs
        contig_stats={}
        stats = parse_stats(get_file_name(input.contig_stats))
        contig_stats['contigs']=stats['reads']
        contig_stats['contig bases']=stats['bases']

        # full length SSUs
        ssu_count=-1
        with open(get_file_name(input.ssu_rrnas)) as INF:
            for line in INF:
                ssu_count+=1
        contig_stats['SSUs']=ssu_count

        # full length LSUs
        lsu_count=-1
        with open(get_file_name(input.lsu_rrnas)) as INF:
            for line in INF:
                lsu_count+=1
        contig_stats['LSUs']=lsu_count

        report={"reads":read_stats,
                "assembly":contig_stats,
                "assembly_name":wildcards.assembly_name}
        with open(output[0],'w') as OUTF:
            OUTF.write(yaml.dump(report, default_flow_style=False))

